{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25aa8a76",
   "metadata": {},
   "source": [
    "這是為了測試對於真實訓練數據我們該採用對於scedule的參數以及diffusion step的一個測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909b7d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from polydiff.diffusion.forward import ExcitedStateDiffusion\n",
    "from polydiff.diffusion.schedules import ExponentialSchedule\n",
    "from polydiff.model import ChemBERTTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b17558a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"/Users/wang-work/polydiffusion/data/smiles.txt\"\n",
    "data = []\n",
    "with open(data_file, \"r\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if line:  # Check if the line is not empty\n",
    "            data.append(line)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c04caff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_diffusion(beta_start=1e-4, beta_end=0.02, num_timesteps=1000, vocab_size=100, mask_token_id=99, pad_token_id=0):\n",
    "    \"\"\"\n",
    "    初始化diffusion過程\n",
    "    \n",
    "    Args:\n",
    "        beta_start: beta的起始值\n",
    "        beta_end: beta的結束值  \n",
    "        num_timesteps: diffusion步數\n",
    "        vocab_size: 詞彙表大小\n",
    "        mask_token_id: mask token ID\n",
    "        pad_token_id: pad token ID\n",
    "    \n",
    "    Returns:\n",
    "        ExcitedStateDiffusion: 初始化好的diffusion實例\n",
    "    \"\"\"\n",
    "    # 創建指數schedule\n",
    "    schedule = ExponentialSchedule(\n",
    "        num_timesteps=num_timesteps,\n",
    "        beta_start=beta_start,\n",
    "        beta_end=beta_end\n",
    "    )\n",
    "    \n",
    "    # 初始化ExcitedStateDiffusion\n",
    "    diffusion = ExcitedStateDiffusion(\n",
    "        schedule=schedule,\n",
    "        vocab_size=vocab_size,\n",
    "        mask_token_id=mask_token_id,\n",
    "        pad_token_id=pad_token_id\n",
    "    )\n",
    "    \n",
    "    print(f\"ExcitedStateDiffusion已初始化！\")\n",
    "    print(f\"- Beta範圍: {beta_start} -> {beta_end}\")\n",
    "    print(f\"- 時間步數: {num_timesteps}\")\n",
    "    print(f\"- 詞彙表大小: {vocab_size}\")\n",
    "    \n",
    "    return diffusion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675952e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_sequences_by_length(data, shortest_count=20, middle_count=50, longest_count=20, random_seed=42):\n",
    "    \"\"\"\n",
    "    從數據中選擇不同長度的序列\n",
    "    \n",
    "    Args:\n",
    "        data: 序列數據列表\n",
    "        shortest_count: 最短序列數量\n",
    "        middle_count: 中間序列數量  \n",
    "        longest_count: 最長序列數量\n",
    "        random_seed: 隨機種子\n",
    "    \n",
    "    Returns:\n",
    "        list: 選中的序列列表\n",
    "    \"\"\"\n",
    "    import random\n",
    "    \n",
    "    # 計算每個序列的長度\n",
    "    data_lengths = [(i, len(seq)) for i, seq in enumerate(data)]\n",
    "    data_lengths.sort(key=lambda x: x[1])\n",
    "    \n",
    "    # 找最短的序列\n",
    "    shortest_sequences = data_lengths[:shortest_count]\n",
    "    \n",
    "    # 找最長的序列\n",
    "    longest_sequences = data_lengths[-longest_count:]\n",
    "    \n",
    "    # 中間隨機選擇序列\n",
    "    middle_range = data_lengths[shortest_count:-longest_count]\n",
    "    random.seed(random_seed)\n",
    "    middle_sequences = random.sample(middle_range, min(middle_count, len(middle_range)))\n",
    "    middle_sequences.sort(key=lambda x: x[1])\n",
    "    \n",
    "    # 收集所有選中的序列\n",
    "    selected_sequences = []\n",
    "    selected_sequences.extend([data[idx] for idx, _ in shortest_sequences])\n",
    "    selected_sequences.extend([data[idx] for idx, _ in middle_sequences])\n",
    "    selected_sequences.extend([data[idx] for idx, _ in longest_sequences])\n",
    "    \n",
    "    return selected_sequences\n",
    "\n",
    "# 運行函數獲取選中的序列\n",
    "selected_sequences = select_sequences_by_length(data)  # Ensure 'data' is defined in a previous cell\n",
    "print(f\"總共選取了 {len(selected_sequences)} 條序列\")\n",
    "selected_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912b7fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"seyonec/ChemBERTa-zinc-base-v1\")\n",
    "def initialize_and_test_diffusion(sequences, \n",
    "                                  tokenizer=tokenizer,\n",
    "                                  beta_start=1e-4, \n",
    "                                  beta_end=0.02, \n",
    "                                  num_timesteps=1000, \n",
    "                                  vocab_size=tokenizer.vocab_size, \n",
    "                                  mask_token_id=tokenizer.mask_token_id, \n",
    "                                  pad_token_id=tokenizer.pad_token_id):\n",
    "    \"\"\"\n",
    "    初始化diffusion過程並測試每個序列在多少步驟後會被完全mask\n",
    "    \n",
    "    Args:\n",
    "        sequences: 要測試的序列列表\n",
    "        beta_start: beta的起始值\n",
    "        beta_end: beta的結束值  \n",
    "        num_timesteps: diffusion步數\n",
    "        vocab_size: 詞彙表大小\n",
    "        mask_token_id: mask token ID\n",
    "        pad_token_id: pad token ID\n",
    "        max_steps: 最大測試步數\n",
    "    \n",
    "    Returns:\n",
    "        tuple: 初始化好的diffusion實例和每個序列的完全mask步數\n",
    "    \"\"\"\n",
    "    # 創建指數schedule\n",
    "    schedule = ExponentialSchedule(\n",
    "        num_timesteps=num_timesteps,\n",
    "        beta_start=beta_start,\n",
    "        beta_end=beta_end\n",
    "    )\n",
    "    \n",
    "    # 初始化ExcitedStateDiffusion\n",
    "    diffusion = ExcitedStateDiffusion(\n",
    "        schedule=schedule,\n",
    "        vocab_size=vocab_size,\n",
    "        mask_token_id=mask_token_id,\n",
    "        pad_token_id=pad_token_id\n",
    "    )\n",
    "    \n",
    "    print(f\"ExcitedStateDiffusion已初始化！\")\n",
    "    print(f\"- Beta範圍: {beta_start} -> {beta_end}\")\n",
    "    print(f\"- 時間步數: {num_timesteps}\")\n",
    "    print(f\"- 詞彙表大小: {vocab_size}\")\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for i, seq in enumerate(sequences):\n",
    "        # tokenize序列\n",
    "        tokens = tokenizer.encode(seq, add_special_tokens=True, return_tensors=\"pt\")\n",
    "        tokens = tokens[:, 1:-1]  # Remove the first and last tokens (0 and 2)\n",
    "        # 測試不同步數\n",
    "        for t in range(1, num_timesteps ):\n",
    "            # 創建時間步張量\n",
    "            timesteps = torch.tensor([t])\n",
    "            \n",
    "            # 應用forward diffusion\n",
    "            noisy_tokens,_ = diffusion.forward_mask_process(tokens, timesteps)\n",
    "            \n",
    "            # 檢查是否完全被mask\n",
    "            mask_token_id = tokenizer.mask_token_id\n",
    "            if (noisy_tokens == mask_token_id).all() and (tokens != tokenizer.pad_token_id).any():\n",
    "                results[seq] = t\n",
    "                break\n",
    "        else:\n",
    "            results[seq] = -99 # 如果沒有完全mask，則記錄最大步數\n",
    "\n",
    "    return diffusion, results\n",
    "\n",
    "beta_start = [0.01, 0.05, 0.1]\n",
    "beta_end = [0.1, 0.2, 0.3]\n",
    "num_timesteps = [20, 30, 40, 50]\n",
    "for b_start in beta_start:\n",
    "    for b_end in beta_end:\n",
    "        for n_steps in num_timesteps:\n",
    "            print(f\"Testing with beta_start={b_start}, beta_end={b_end}, num_timesteps={n_steps}\")\n",
    "            diffusion, results = initialize_and_test_diffusion(\n",
    "                selected_sequences,\n",
    "                tokenizer=tokenizer,\n",
    "                beta_start=b_start,\n",
    "                beta_end=b_end,\n",
    "                num_timesteps=n_steps\n",
    "            )\n",
    "            # Create a scatter plot for token lengths vs diffusion steps\n",
    "            import matplotlib.pyplot as plt\n",
    "            token_lengths = [len(tokenizer.encode(seq, add_special_tokens=True)) - 2 for seq in selected_sequences]\n",
    "\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.scatter(token_lengths, list(results.values()), alpha=0.6)\n",
    "            plt.title('Token Length vs Diffusion Steps')\n",
    "            plt.xlabel('Token Length')\n",
    "            plt.ylabel('Diffusion Steps')\n",
    "            plt.grid()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59792f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "polydiff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
